# -*- coding: utf-8 -*-
"""DescriptionNaverNews.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17FQfhX_E666ExUrmMm5d2LtYFSq6m7C6
"""

#cleanedrefugeenewstitles.csv
#cleanedmigrantnewstitles.csv
#cleanedimmigrantnewstitles.csv
#cleanedmarriagemigrantnewstitles.csv
#cleanedillmigrantnewstitles.csv
#cleanedwomenmigrantnewstitles.csv
#cleanedforeignersnewstitles.csv
#cleanedforeignermigrantsnewstitles.csv
#cleanedirregularmigrantsnewstitles.csv
#cleanedimmigrantworkersnewstitles.csv


#cleanedillmigrantnewstitles.csv
#cleanedrefugeenewstitles.csv
#cleanedmarriagemigrantnewstitles.csv
#cleanedwomenmigrantnewstitles.csv


#cleanedmigrantnewstitles.csv
#cleanedimmigrantnewstitles.csv
#cleanedforeignersnewstitles.csv
#cleanedforeignermigrantsnewstitles.csv
#cleanedimmigrantworkersnewstitles.csv

import pandas as pd


df1 = pd.read_csv('/content/drive/MyDrive/migration/cleanedrefugeenewstitles.csv', lineterminator='\n')
df2 = pd.read_csv('/content/drive/MyDrive/migration/cleanedmigrantnewstitles.csv', lineterminator='\n')
df3 = pd.read_csv('/content/drive/MyDrive/migration/cleanedimmigrantnewstitles.csv', lineterminator='\n')
df4 = pd.read_csv('/content/drive/MyDrive/migration/cleanedmarriagemigrantnewstitles.csv', lineterminator='\n')
df5 = pd.read_csv('/content/drive/MyDrive/migration/cleanedillmigrantnewstitles.csv', lineterminator='\n')
df6 = pd.read_csv('/content/drive/MyDrive/migration/cleanedwomenmigrantnewstitles.csv', lineterminator='\n')
df7 = pd.read_csv('/content/drive/MyDrive/migration/cleanedforeignersnewstitles.csv', lineterminator='\n')
df8 = pd.read_csv('/content/drive/MyDrive/migration/cleanedforeignermigrantsnewstitles.csv', lineterminator='\n')
df9 = pd.read_csv('/content/drive/MyDrive/migration/cleanedirregularmigrantsnewstitles.csv', lineterminator='\n')
df10 = pd.read_csv('/content/drive/MyDrive/migration/cleanedimmigrantworkersnewstitles.csv', lineterminator='\n')



#df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10], axis=0, ignore_index=True, sort=True)
df = pd.concat([df4, df6], axis=0, ignore_index=True, sort=True)
df.head()

df.to_csv('/content/drive/MyDrive/migration/marriageandwomennewsarticles.csv')

#News scrape
'''

import os
import sys
import urllib.request


client_id = "CX9harkKYlwKQsq4kCg0"
client_secret = "gNYNwIlniZ"

file_path = "./tesst.json"

encText = urllib.parse.quote("이주노동자")



url = "https://openapi.naver.com/v1/search/news.json?display=100&start=1000&sort=sim&query=" + encText


request = urllib.request.Request(url)
request.add_header("X-Naver-Client-Id",client_id)
request.add_header("X-Naver-Client-Secret",client_secret)
response = urllib.request.urlopen(request)
rescode = response.getcode()
if(rescode==200):
    response_body = response.read()
    print(response_body.decode('utf-8'))
else:
    print("Error Code:" + rescode)


import pandas as pd
df = pd.read_fwf('/content/drive/MyDrive/migration/이주노동자.txt')

df.to_csv('/content/drive/MyDrive/migration/immigrantworkersnewstitles.csv')

refugeenewstitles.csv

migrantnewstitles.csv

immigrantnewstitles.csv

marriagemigrantnewstitles.csv

illmigrantnewstitles.csv

womenmigrantnewstitles.csv

foreignersnewstitles.csv

foreignermigrantsnewstitles.csv

irregularmigrantsnewstitles.csv

immigrantworkersnewstitles.csv

'''

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd


df = pd.read_csv('/content/drive/MyDrive/migration/immigrantworkersnewstitles.csv', lineterminator='\n')
#refugeenewstitles.csv
#migrantnewstitles.csv
#immigrantnewstitles.csv
#marriagemigrantnewstitles.csv
#illmigrantnewstitles.csv

#womenmigrantnewstitles.csv
#foreignersnewstitles.csv
#foreignermigrantsnewstitles.csv
#irregularmigrantsnewstitles.csv
#immigrantworkersnewstitles.csv


column_names = list(df.columns.values)

for column_headers in df.columns:
    print(column_headers)

df.head()

df = df.drop(df.columns[[0, 1, 2]], axis=1)
df.rename(columns={"Unnamed: 2": "newstitle"}, inplace=True)
df.head()

df2 = df[df['newstitle'].str.contains('description|pubDate', na = False)]
df2.head()

df2.to_csv('/content/drive/MyDrive/migration/newsarticles/datedimmigrantworkersnewstitles.csv')
#refugeenewstitles.csv
#migrantnewstitles.csv
#immigrantnewstitles.csv
#marriagemigrantnewstitles.csv
#illmigrantnewstitles.csv
#womenmigrantnewstitles.csv
#foreignersnewstitles.csv
#foreignermigrantsnewstitles.csv
#irregularmigrantsnewstitles.csv
#immigrantworkersnewstitles.csv

import pandas as pd


df = pd.read_csv('/content/drive/MyDrive/migration/newsarticles/datedimmigrantworkersnewstitles.csv', lineterminator='\n')
df.head()

df2.to_csv('/content/drive/MyDrive/migration/newsarticles/datedimmigrantworkersnewstitles.csv')
#refugeenewstitles.csv
#migrantnewstitles.csv
#immigrantnewstitles.csv
#marriagemigrantnewstitles.csv
#illmigrantnewstitles.csv
#womenmigrantnewstitles.csv
#foreignersnewstitles.csv
#foreignermigrantsnewstitles.csv
#irregularmigrantsnewstitles.csv
#immigrantworkersnewstitles.csv

#df2["pubDate"] = df2["newstitle"].shift()
#df2["pubDate"] = df2[df2['newstitle'].str.contains('pubDate', na=False)]
#df2.head()

#merge consecutive rows
#then divide by pubDate

df3 = df[df['newstitle'].str.contains('title|description', na = False)]
df3.head()

df3.to_csv('/content/drive/MyDrive/migration/titleimmigrantworkersnewstitles.csv')

#if want to try over time
#df2 = df.join(df.newstitle.shift(-1).rename('pubDate')).dropna()
#df2.head()

import pandas as pd
import glob
import os
import re
import numpy as np
from datetime import datetime
import dateutil.parser as parser

df = pd.read_csv('/content/drive/MyDrive/migration/titleimmigrantworkersnewstitles.csv', lineterminator='\n')
#df=df.set_axis(['newstitle', 'removed'], axis=1, inplace=False)[["newstitle"]].astype(str)


#make a function to clean text from unwanted characters
file = open('/content/drive/MyDrive/migration/stopwords.txt', 'r')
words = file.read()
file.close()
stopwords = list(words.split())

def remove_stopwords(text):
    text = [word for word in text.lower().split() if word not in stopwords]
    text = ''.join(text[0:])
    return text

def clean_text(text):
    #Remove hyper links
    text = re.sub(r'https?:\/\/\S+', ' ', text)
    #Remove @mentions
    text = re.sub(r'@[A-Za-z0-9]+', ' ', text) #(if the below works, we can erase this)
    # Remove user @ references and '#' from tweet
    text = re.sub(r'\@\w+|\#|\d+', '', text)
    # Remove noice
    text = re.sub(r'[-_:,\'"+RT]|[a-z]|[📍📌💬🌏]|[✔▶]|\[|\]|\*|\(|\)|\.\.\.+|[…]|\.\.+', '', text)
    # Remove extra brakets
    text=text.strip()
    # Remove urls
    text = re.sub(r"http\S+|www\S+|https\S+", '', text, flags=re.MULTILINE)
    # Remove Stop words
    text=remove_stopwords(text)
    return text

# Apply the clean_text function to the 'Tweet' column
df['cleanedtext']=df['newstitle'].apply(clean_text)

df.head()

df.to_csv('/content/drive/MyDrive/migration/cleanedimmigrantworkersnewstitles.csv')

###################now donwload and use on remote for bertopic

#trials but failed:

from wordcloud import WordCloud
from wordcloud import ImageColorGenerator
from wordcloud import STOPWORDS
import matplotlib.pyplot as plt
import pandas as pd
data = pd.read_csv('/content/drive/MyDrive/migration/cleanednewsarticles.csv', lineterminator='\n')
df.head()

data =df['cleanedtext']

text = " ".join(i for i in data)
stopwords = set(STOPWORDS)
wordcloud = WordCloud(stopwords=stopwords, background_color="white").generate(text)
plt.figure( figsize=(15,10))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show()

# Commented out IPython magic to ensure Python compatibility.
!pip install bertopic
!pip install -q konlpy
!pip install bertopic[visualization]
!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git
# %cd Mecab-ko-for-Google-Colab
!bash install_mecab-ko_on_colab190912.sh

from google.colab import drive
drive.mount('/content/drive')

import re
import pandas as pd
import numpy as np
from tqdm import tqdm
from sklearn.feature_extraction.text import CountVectorizer
from konlpy.tag import Mecab
from bertopic import BERTopic

df = pd.read_csv('/content/drive/MyDrive/migration/cleanednewsarticles.csv', lineterminator='\n')

df=df.dropna()


documents = [line.strip() for line in df.cleanedtext]
preprocessed_documents = []

for line in tqdm(documents):
  if line and not line.replace(' ', '').isdecimal():
    preprocessed_documents.append(line)

text=''.join(preprocessed_documents[:10000])
text=text.split('.')

class CustomTokenizer:
    def __init__(self, tagger):
        self.tagger = tagger
    def __call__(self, sent):
        sent = sent[:1000000]
        #word_tokens = self.tagger.morphs(sent)
        word_tokens = self.tagger.nouns(sent) #to have only nouns
        result = [word for word in word_tokens if len(word) > 1]
        return result

from bertopic import BERTopic
import pandas as pd
'''
seed_topic_list = [['실업', '일자리', '작업 경쟁','취업 경쟁','직장 잃','경쟁'], #1. Common Arguments against Immigration: “immigrants take jobs, lower wages, hurt the poor” (ref: https://www.cato.org/blog/14-most-common-arguments-against-immigration-why-theyre-wrong)
                   ['건강 보험', '병원', '복지','보건의료사비스', '보건의료', '보건의료요구','의료 혜택',  '보험 혜택',  '의료', '건강', '의료혜택','보건의료정책','IHS', 'NHS','의료 서비스', '사회복지'], #2. Common Arguments against Immigration : “ abuse welfare”
                   ['세금','불경기'], #3. Common Arguments against Immigration: “increase budget deficit and government debt”
                   ['한국어 실력', '문화 교류','통합','언어장벽', '동화','사회통합 프로그램','공동'], #4.Common Arguments against Immigration: “ don’t assimilate, integrate”community
                   ['불법','범죄','위험', '살인', '강도', '절도', '매춘', '마약', '사이버 범죄', '텔레뱅킹 사기', '피싱', '외국인 범죄', '위조범', '밀수품', '산업연수생 범죄'], #5. Common Arguments against Immigration: “source of crime”
                   ['테러','테러분자','테러리즘','테러리스트','사보타주'], #6.Common Arguments against Immigration: “terrorism”
                   ['민족주의','한국적 가치관, 한국성','국가 이미지','한국 이미지'], #7.Common Arguments against Immigration: national sovereignty
                   ['정부','법무부','윤석열','문재인','박근혜','이명박','노무현','김대중','대통령','통치'], #8.ruling class - government
                   ['국적','교포', '미국', '일본', '이집트',  '주전자','고려인', '러시아','흑인','아랍','라틴아메리카 ' , '베트남', '둥포', '백인', '조선족', '러시아인', '미국인', '유럽인', '서구인','서양인', '동남아시아인', '동남아인', '우즈벡인', '우즈베키스탄 이주', '중국인', '중국', '아프리카', '인도', '우크라이나',  '중동', '몽골인', '몽골', '탈북이주민', '북한이탈주민'], #9.dividing the working class with identity politics:racism and ethnicity 인종
                   ['이주여성','여성이주노동자','여성','여자', '젠더'], #10.dividing the working class with identity politics: gender discrimination 성별
                   ['MTU', '조합', '이주노동희망센터', '이민자 센터', '연대', '이주노동자노동조합', '이주노조', '이주노동자 노동조합', '이주민센터 친구','상담'], #11.uniting the working class with union
                   ['국제결혼', '외국인 신부', '결혼이민자', '결혼이민','결혼이주자', '결혼 중개업', '이민자 부모','결혼', '이혼', '아내', '남편', '신부', '가정 폭력', '가족 폭력'], #12.dividing migrants by migrant status and place in the online migration debate: marriage
                   ['가족','다문화주의','외국인 아동','다문화 가정','이민자 부모', '임산부','임신','어린이', '부모님','다문화가족'], #13.Family
                   ['무슬림','이슬람교도','이슬람','무슬리마'], #14. divide by religion
                   ['선생님','영어 선생님', '부자', '사업가','투자자','교수','상용 비자'], #15.status: high payed worker
                   ['농장','건설','선박', '어업','E9', '고용허가제', '서비스업', '농축산업', '건설업','제조업','건설공사', '작물재배업','축산업','양식어업','소금채취업', ' 비전문취업','건설폐기물 처리업','육체노동','공장', '건설노동자', '계절 노동자', '3D 업종','산업연수생 시스템'], #16.status: low payed workers in 3d industries
                   ['가사도우미', '입주도우미', '육아도우미' , '간병도우미', '베이비시터', '외국인 가사도우미', '돌봄도우미', '간병인', '도우미','요식업','식업'], #17.status: gendered work in service industry, nurse, cleaning staff
                   ['관광객', '여행', '문화', '여행자','관광'], #18.status: tourist
                   ['학생', '학교', '대학교', '대학생', '교환 학생','유학비자', '유학', '어학연수', '교환학생', '연구유학'], #19.status: student
                   ['탈북자','북한이탈주민','탈북','탈북자','탈북민','새터민','북한이탈주민'], #20.north korea refugees
                   ['불법체류자','불법체류 외국인', '불법체류', '미등록', '미등록 이주자', '불쳬자','미등록외국인근로자', '외국인 불법 근로자','무허가 노동자'], #21.status: undocumented immigration
                   ['난민','피난자', '예멘', '미얀마','파키스탄','방글라데시','에티오피아','망명 신청자'], #22.status: refugee
                   ['변호사', '법원','비자', '법', '이민법','시민권', '노동법','국적법', '이민 정책', '근로기준법'], #23.immigration law
                   ['출입국관리소', '비자연장', '비자유형변경', '비자신청', '영주권', '체류허가', '비자'], #24.administration
                   ['저임금 노동', '값싼 노동자', '저임금', '최저임금','고용','계급','자본'], #25.wages and work, working class in capitalism
                   ['노동 착취','남용', '착취', '사고', '직장 괴롭힘', '괴롭힘', '근로환경', '작업 조건','폭력','노예'], #26.human rights abuse
                   ['노동시간', '복지', '시설', '산업재해', '임금체불', '시간외 수당', '해고','부상 보상'], #27.working conditions
                   ['경찰단속', '단속','합동단속', '정부합동단속', '단속추방','추방','강제추방','외국인보호소','경찰', '감옥','국경검사','한국경찰','구속'], #28.police state, border, deportation, expulsion
                   ['차별','차별금지','외국인 혐오','소수자',' 배제','불평등','계층','고정관념','낙인','선입견','인종차별','기본권', '평등', '불평등', '편견','인권'], #29.discrimination awareness
                   ['경제', '경제이주', '경제적 이득', '노동수요','노동력 부족','이윤']] #30.economy

 '''
custom_tokenizer = CustomTokenizer(Mecab())
vectorizer = CountVectorizer(tokenizer=custom_tokenizer, max_features=3000)

from bertopic import BERTopic

model = BERTopic(embedding_model="sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens", \
                 vectorizer_model=vectorizer,
                 #seed_topic_list=seed_topic_list,
                 min_topic_size=35,
                 nr_topics=31,
                 top_n_words=10,
                 calculate_probabilities=True)

topics, probs = model.fit_transform(text)

model.save('/content/drive/MyDrive/migration/mars7model.h5')

model.load('/content/drive/MyDrive/migration/mars7model.h5')

topics_over_time = model.topics_over_time(tweets, timestamps)

model.visualize_topics_over_time(topics_over_time, top_n_topics=30)

model.visualize_topics()
#model.visualize_topics(top_n_topics=10)

model.visualize_distribution(probs[0])

model.get_representative_docs()

model.get_representative_docs(1)

for i in range(0, 30):
  print(i,'번째 토픽 :', model.get_topic(i))

model.get_topic_info()

model.get_topics() #access all topics

model.visualize_hierarchy() #topic hierarchy

model.visualize_barchart() #Visualize Topic Terms

model.visualize_heatmap() #Visualize Topic Similarity

model.visualize_term_rank() #Visualize Term Score Decline

model.generate_topic_labels() #Generate topic labels

#Find topics that are similar to specified term: return top x topics that are semantically most similar to an input query term
#from: https://towardsdatascience.com/let-us-extract-some-topics-from-text-data-part-iv-bertopic-46ddf3c91622

# x most similar topics to specified word
similar_topics, similarity = \
model.find_topics("여성", top_n = 10)

print("Most Similar Topic Info: \n{}".format(model.get_topic(similar_topics[0])))
print("Similarity Score: {}".format(similarity[0]))

print("\n Most Similar Topic Info: \n{}".format(model.get_topic(similar_topics[1])))
print("Similarity Score: {}".format(similarity[1]))

print("\n Most Similar Topic Info: \n{}".format(model.get_topic(similar_topics[2])))
print("Similarity Score: {}".format(similarity[2]))