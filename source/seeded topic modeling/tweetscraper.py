# -*- coding: utf-8 -*-
"""tweetscraper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_i6NS0-F1m8Awzt8afINsgv0IwrP0Zmm
"""

#DATA SCRAPE TWEETS (method by 혁채)
#twitter scrape all
#in command: pip3 install snscrape
#Keyword queries = basket of words for "migrant":
"""
비정규 이민자
난민
불법 이민자
이민
이주 노동자
고용허가제
비자
이주자
이주민
이민자
외국인
불법체류자
미등록이주민
외국인노동자
이주노동자
...etc
"""
#in Word embeddings, find vectors to those basket of words (depending on gender and ethnicity/nationality)
#basket of word for "reason for migration" : "노동하기 위해서, 결혼을 통해서, 해외의 동포, 난민, 유학생"
#legal status : "경찰, 비자, 불법, 비정규"
#..etc

#snscrape --jsonl --progress --max-results 5000000000 twitter-search "이주민 since:2009-12-01 until:2022-07-26" > ijoumintweets.json = 72 678 results (very low?)
#snscrape --jsonl --progress --max-results 5000000000 twitter-search "난민 since:2009-12-01 until:2022-07-26" > nanmintweets.json = 348 863
#snscrape --jsonl --progress --max-results 5000000000 twitter-search "외국인 since:2009-12-01 until:2022-07-26" > ouaigugintweets.json = n
#snscrape --jsonl --progress --max-results 5000000000 twitter-search "이민자 since:2009-12-01 until:2022-07-26" > iminjatweets.json = 77 013
#snscrape --jsonl --progress --max-results 5000000000 twitter-search "노동자 since:2009-12-01 until:2022-07-26" > nodongjatweets.json =
#snscrape --jsonl --progress --max-results 5000000000 twitter-search "이민 since:2009-12-01 until:2022-07-26" > imintweets.json =
#snscrape --jsonl --progress --max-results 5000000000 twitter-search "불법체류자 since:2009-12-01 until:2022-07-26" > bulbeopcheliujatweets.json = 34 759
#snscrape --jsonl --progress --max-results 5000000000 twitter-search "미등록이주민 since:2009-12-01 until:2022-07-26" > mideunglokijoumintweets.json = 962
#snscrape --jsonl --progress --max-results 5000000000 twitter-search "외국인노동자 since:2009-12-01 until:2022-07-26" > ouaiguginnodongjatweets.json = 58005
#snscrape --jsonl --progress --max-results 5000000000 twitter-search "이주노동자 since:2009-12-01 until:2022-07-26" > ijounodongjatweets.json = 46 422
#snscrape --jsonl --progress --max-results 5000000000 twitter-search "이주자 since:2009-12-01 until:2022-07-26" > ijoujatweets.json = 23 092
#snscrape --jsonl --progress --max-results 5000000000 twitter-search "고용허가제 since:2009-12-01 until:2022-07-26" > goyoengheogajetweets.json = 2 425


#snscrape --jsonl --progress --max-results 5000000000 twitter-search "xxxx since:2009-12-01 until:2022-07-26" > xxxxtweets.json =

#add json file to to google drive
#add the json file to the collab environment

#TRIAL ON SMALL DATASET of small dataset: "trialtest.json"

import pandas as pd
tweets_df = pd.read_json('trialtest.json', lines=True)

attributes_container = []

# Using TwitterSearchScraper to scrape data and append tweets to list
for i in range(tweets_df.shape[0]):
    if i==tweets_df.shape[0]:
      break
    attributes_container.append([tweets_df.loc[i]['date'], tweets_df.loc[i]['likeCount'], tweets_df.loc[i]['content']])

# Creating a dataframe to load the list
tweets_df = pd.DataFrame(attributes_container, columns=["Date", "Likes", "Tweet"])
tweets_df

#now as data as list in dataframe
#ADD: id (user , replycount , retweetCount  quoteCount retweetedTweet quotedTweet mentionedUsers)